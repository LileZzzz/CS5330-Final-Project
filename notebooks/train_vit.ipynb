{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iJmsn3WlZolG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJmsn3WlZolG",
        "outputId": "0d51fba6-8ba7-462d-b954-5953942db81a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.21.3-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==2.21.3 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.21.3-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.14.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.40)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading databricks_sdk-0.50.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (1.31.1)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (2.11.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.3->mlflow) (4.13.1)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (2.38.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.3->mlflow)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.3->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (0.52b1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (2025.1.31)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.21.3->mlflow) (0.14.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (4.9)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.21.3-py3-none-any.whl (28.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.21.3-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.50.0-py3-none-any.whl (692 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m692.3/692.3 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, gunicorn, graphql-core, starlette, graphql-relay, docker, alembic, graphene, fastapi, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed alembic-1.15.2 databricks-sdk-0.50.0 docker-7.1.0 fastapi-0.115.12 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.21.3 mlflow-skinny-2.21.3 starlette-0.46.2 uvicorn-0.34.1\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.4-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.4\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow\n",
        "!pip install pyngrok\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04e11722",
      "metadata": {
        "id": "04e11722"
      },
      "outputs": [],
      "source": [
        "# This notebook is used to train and tune the model via Colab\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torchvision.models import vit_b_16\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from mlflow.tracking import MlflowClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6828e25",
      "metadata": {
        "id": "a6828e25"
      },
      "outputs": [],
      "source": [
        "def load_data(batch_size=32):\n",
        "    # Define the transformation (Imagnet mean and std)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Load the dataset\n",
        "    dataset = datasets.EuroSAT(root='./data', download=True, transform=transform)\n",
        "\n",
        "    # Split the dataset into train, validation, test sets\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False)\n",
        "\n",
        "    return dataset, train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fb2354e",
      "metadata": {
        "id": "8fb2354e"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained vit model\n",
        "def load_vit(num_classes=10, unfreeze=5):\n",
        "    model = vit_b_16(weights='DEFAULT')\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze the last few layers\n",
        "    if unfreeze > 0:\n",
        "        encoder_layers = model.encoder.layers\n",
        "        number_of_layers = len(encoder_layers)\n",
        "\n",
        "        for i in range(number_of_layers - unfreeze, number_of_layers):\n",
        "            for param in encoder_layers[i].parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "    # replace the classifier head\n",
        "    num_features = model.heads.head.in_features\n",
        "    model.heads.head = torch.nn.Linear(num_features, num_classes)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdffcff8",
      "metadata": {
        "id": "fdffcff8"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_size = 0\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total_size += labels.size(0)\n",
        "    # Calculate average loss and accuracy\n",
        "    return total_loss / total_size, 100 * correct / total_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeaa605d",
      "metadata": {
        "id": "eeaa605d"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "def eval(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total_size = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total_size += labels.size(0)\n",
        "    # Calculate average loss and accuracy\n",
        "    return total_loss / total_size, 100 * correct / total_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "054bb023",
      "metadata": {
        "id": "054bb023"
      },
      "outputs": [],
      "source": [
        "# Tune the model\n",
        "def objective(trial):\n",
        "    lr = trial.suggest_float('lr', 1e-5, 5e-5, log=True)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64])\n",
        "    unfreeze = trial.suggest_categorical('unfreeze', [0, 3])\n",
        "    weight_decay = trial.suggest_categorical('weight_decay', [0.0, 0.01])\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
        "\n",
        "    # Load the data\n",
        "    dataset, train_dataloader, val_dataloader, test_dataloader = load_data(batch_size)\n",
        "\n",
        "    # Load the model\n",
        "    model = load_vit(num_classes=len(dataset.classes), unfreeze=unfreeze).to(device)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
        "        # Log parameters\n",
        "        mlflow.log_param(\"lr\", lr)\n",
        "        mlflow.log_param(\"batch_size\", batch_size)\n",
        "        mlflow.log_param(\"unfreeze\", unfreeze)\n",
        "        mlflow.log_param(\"weight_decay\", weight_decay)\n",
        "\n",
        "        patience = 2\n",
        "        patience_cnt = 0\n",
        "        best_val_acc = 0\n",
        "        epochs = 5\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            train_loss, train_acc = train(model, train_dataloader, criterion, optimizer, device)\n",
        "            val_loss, val_acc = eval(model, val_dataloader, criterion, device)\n",
        "            \n",
        "            # Log metrics\n",
        "            \n",
        "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
        "            mlflow.log_metric(\"train_acc\", train_acc, step=epoch)\n",
        "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
        "            mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            trial.report(val_acc, epoch)\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_cnt = 0\n",
        "            else:\n",
        "                patience_cnt += 1\n",
        "\n",
        "                if patience_cnt >= patience:\n",
        "                    break\n",
        "\n",
        "            if trial.should_prune():\n",
        "                raise optuna.TrialPruned()\n",
        "\n",
        "    return best_val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d02a1ad",
      "metadata": {
        "id": "4d02a1ad"
      },
      "outputs": [],
      "source": [
        "# visualize the predictions by running the model on the test set\n",
        "def visualize_predictions(model, dataloader, device, dataset, n_samples=25):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # visualize the first n_samples images\n",
        "            fig, axes = plt.subplots(5, 5, figsize=(30, 20))\n",
        "            for i in range(n_samples):\n",
        "                ax = axes[i // 5, i % 5]\n",
        "                # unnormalize the image\n",
        "                image = images[i].cpu().permute(1, 2, 0)\n",
        "                image = image * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
        "                image = image.clamp(0, 1)\n",
        "                ax.imshow(image)\n",
        "                # set the title to the predicted and true label not number\n",
        "                ax.set_title(f\"Pred: {dataset.classes[preds[i].item()]}, True: {dataset.classes[labels[i].item()]}\")\n",
        "                ax.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31ac10d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31ac10d9",
        "outputId": "04b528b4-2e15-4043-8943-fae8145874bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/04/14 18:29:21 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2025/04/14 18:29:21 INFO mlflow.store.db.utils: Updating database tables\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
            "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
            "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
            "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
            "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
            "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
            "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
            "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
            "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
            "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
            "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
            "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
            "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
            "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
            "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
            "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
            "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
            "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
            "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
            "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
            "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "2025/04/14 18:29:22 INFO mlflow.tracking.fluent: Experiment with name 'EuroSAT_ViT_Classification' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='/content/mlruns/1', creation_time=1744655362619, experiment_id='1', last_update_time=1744655362619, lifecycle_stage='active', name='EuroSAT_ViT_Classification', tags={}>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import subprocess\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "\n",
        "# Fix the seed\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Set up MLflow tracking server\n",
        "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
        "EXPERIMENT_NAME = \"EuroSAT_ViT_Classification\"\n",
        "\n",
        "subprocess.Popen([\"mlflow\", \"ui\", \"--backend-store-uri\", MLFLOW_TRACKING_URI, \"--port\", \"5000\"])\n",
        "\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xrop1RVuaPl0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrop1RVuaPl0",
        "outputId": "c1e35c7f-0129-4466-abf7-c758c8f3ed13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "··········\n"
          ]
        }
      ],
      "source": [
        "# Set up ngrok to expose the MLflow UI\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "conf.get_default().auth_token = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZKARbj86acvt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKARbj86acvt",
        "outputId": "482d7670-ddb5-44ee-c06b-d33012686bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * ngrok tunnel \"https://299f-34-142-227-62.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n"
          ]
        }
      ],
      "source": [
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f' * ngrok tunnel \"{public_url}\" -> \"http://127.0.0.1:{port}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cff6d9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cff6d9c",
        "outputId": "62a5c86f-6993-4e86-fc69-da8541c6c7b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 18:29:46,780] A new study created in memory with name: EuroSAT_ViT_Classification\n",
            "100%|██████████| 94.3M/94.3M [00:00<00:00, 387MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:05<00:00, 67.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Train Loss: 1.6406, Train Acc: 58.49%, Val Loss: 1.1266, Val Acc: 80.54%\n",
            "Epoch [2/5], Train Loss: 0.8918, Train Acc: 84.54%, Val Loss: 0.7143, Val Acc: 87.16%\n",
            "Epoch [3/5], Train Loss: 0.6185, Train Acc: 88.16%, Val Loss: 0.5335, Val Acc: 89.98%\n",
            "Epoch [4/5], Train Loss: 0.4847, Train Acc: 90.02%, Val Loss: 0.4336, Val Acc: 91.04%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 18:55:15,866] Trial 0 finished with value: 91.92592592592592 and parameters: {'lr': 3.172390142984219e-05, 'batch_size': 32, 'unfreeze': 0, 'weight_decay': 0.0}. Best is trial 0 with value: 91.92592592592592.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Train Loss: 0.4055, Train Acc: 91.13%, Val Loss: 0.3708, Val Acc: 91.93%\n",
            "Epoch [1/5], Train Loss: 0.6183, Train Acc: 85.43%, Val Loss: 0.1858, Val Acc: 94.77%\n",
            "Epoch [2/5], Train Loss: 0.1202, Train Acc: 96.68%, Val Loss: 0.1158, Val Acc: 96.57%\n",
            "Epoch [3/5], Train Loss: 0.0719, Train Acc: 98.09%, Val Loss: 0.0935, Val Acc: 97.23%\n",
            "Epoch [4/5], Train Loss: 0.0475, Train Acc: 98.78%, Val Loss: 0.0890, Val Acc: 97.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 19:28:57,082] Trial 1 finished with value: 97.38271604938272 and parameters: {'lr': 1.1703764483606674e-05, 'batch_size': 64, 'unfreeze': 3, 'weight_decay': 0.0}. Best is trial 1 with value: 97.38271604938272.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Train Loss: 0.0311, Train Acc: 99.25%, Val Loss: 0.0978, Val Acc: 97.23%\n",
            "Epoch [1/5], Train Loss: 0.3035, Train Acc: 91.95%, Val Loss: 0.1062, Val Acc: 96.79%\n",
            "Epoch [2/5], Train Loss: 0.0705, Train Acc: 97.85%, Val Loss: 0.0851, Val Acc: 97.09%\n",
            "Epoch [3/5], Train Loss: 0.0377, Train Acc: 98.90%, Val Loss: 0.0781, Val Acc: 97.65%\n",
            "Epoch [4/5], Train Loss: 0.0191, Train Acc: 99.53%, Val Loss: 0.0861, Val Acc: 97.26%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 20:02:32,053] Trial 2 finished with value: 97.65432098765432 and parameters: {'lr': 2.2992169210769673e-05, 'batch_size': 32, 'unfreeze': 3, 'weight_decay': 0.0}. Best is trial 2 with value: 97.65432098765432.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Train Loss: 0.0123, Train Acc: 99.71%, Val Loss: 0.0824, Val Acc: 97.63%\n",
            "Epoch [1/5], Train Loss: 0.2718, Train Acc: 92.78%, Val Loss: 0.1090, Val Acc: 96.79%\n",
            "Epoch [2/5], Train Loss: 0.0569, Train Acc: 98.26%, Val Loss: 0.0736, Val Acc: 97.75%\n",
            "Epoch [3/5], Train Loss: 0.0292, Train Acc: 99.14%, Val Loss: 0.0839, Val Acc: 97.28%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 20:29:28,103] Trial 3 finished with value: 97.75308641975309 and parameters: {'lr': 4.721786288863328e-05, 'batch_size': 64, 'unfreeze': 3, 'weight_decay': 0.01}. Best is trial 3 with value: 97.75308641975309.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/5], Train Loss: 0.0170, Train Acc: 99.54%, Val Loss: 0.0995, Val Acc: 97.21%\n",
            "Epoch [1/5], Train Loss: 0.6402, Train Acc: 85.11%, Val Loss: 0.1996, Val Acc: 94.96%\n",
            "Epoch [2/5], Train Loss: 0.1342, Train Acc: 96.29%, Val Loss: 0.1294, Val Acc: 96.05%\n",
            "Epoch [3/5], Train Loss: 0.0816, Train Acc: 97.61%, Val Loss: 0.1114, Val Acc: 96.49%\n",
            "Epoch [4/5], Train Loss: 0.0561, Train Acc: 98.44%, Val Loss: 0.0982, Val Acc: 96.86%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 21:03:05,792] Trial 4 finished with value: 96.88888888888889 and parameters: {'lr': 1.022305809475511e-05, 'batch_size': 64, 'unfreeze': 3, 'weight_decay': 0.0}. Best is trial 3 with value: 97.75308641975309.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Train Loss: 0.0388, Train Acc: 99.15%, Val Loss: 0.0910, Val Acc: 96.89%\n",
            "Epoch [1/5], Train Loss: 0.3781, Train Acc: 90.34%, Val Loss: 0.1107, Val Acc: 96.96%\n",
            "Epoch [2/5], Train Loss: 0.0822, Train Acc: 97.56%, Val Loss: 0.0790, Val Acc: 97.51%\n",
            "Epoch [3/5], Train Loss: 0.0442, Train Acc: 98.76%, Val Loss: 0.0668, Val Acc: 97.80%\n",
            "Epoch [4/5], Train Loss: 0.0252, Train Acc: 99.33%, Val Loss: 0.1137, Val Acc: 96.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 21:36:42,358] Trial 5 finished with value: 97.87654320987654 and parameters: {'lr': 2.5342001417793284e-05, 'batch_size': 64, 'unfreeze': 3, 'weight_decay': 0.01}. Best is trial 5 with value: 97.87654320987654.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/5], Train Loss: 0.0175, Train Acc: 99.58%, Val Loss: 0.0653, Val Acc: 97.88%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 21:41:35,654] Trial 6 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Train Loss: 2.0401, Train Acc: 32.80%, Val Loss: 1.7613, Val Acc: 53.31%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 21:46:38,890] Trial 7 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Train Loss: 2.1119, Train Acc: 29.31%, Val Loss: 1.8266, Val Acc: 51.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 21:51:42,476] Trial 8 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Train Loss: 1.4306, Train Acc: 64.98%, Val Loss: 0.8820, Val Acc: 83.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-04-14 21:56:35,526] Trial 9 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Train Loss: 2.2477, Train Acc: 20.22%, Val Loss: 2.0563, Val Acc: 31.83%\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\", study_name=EXPERIMENT_NAME)\n",
        "study.optimize(objective, n_trials=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q58spnZiUpqF",
      "metadata": {
        "id": "Q58spnZiUpqF"
      },
      "outputs": [],
      "source": [
        "client = MlflowClient()\n",
        "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
        "best_run = client.search_runs(experiment_ids=experiment.experiment_id, order_by=[\"metrics.val_acc DESC\"], max_results=3)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZzTsEfFDV2Es",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzTsEfFDV2Es",
        "outputId": "7d77447a-71d5-4bc7-8e17-da56e92f9b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Run : 2e9cd812af4c4257a4cb7986bb05a39b\n",
            "Status: FINISHED\n",
            "Metrics:\n",
            "  train_loss: 0.017508617192950278\n",
            "  train_acc: 99.57671957671958\n",
            "  val_loss: 0.0653166193963477\n",
            "  val_acc: 97.87654320987654\n",
            "Params:\n",
            "  lr: 2.5342001417793284e-05\n",
            "  batch_size: 64\n",
            "  unfreeze: 3\n",
            "  weight_decay: 0.01\n"
          ]
        }
      ],
      "source": [
        "# Print information for the single best run\n",
        "run_id = best_run.info.run_id\n",
        "metrics = best_run.data.metrics\n",
        "best_params = best_run.data.params\n",
        "status = best_run.info.status\n",
        "\n",
        "print(f\"\\nRun : {run_id}\")\n",
        "print(f\"Status: {status}\")\n",
        "print(\"Metrics:\")\n",
        "for key, value in metrics.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(\"Params:\")\n",
        "for key, value in best_params.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GOhuhZPFUrcv",
      "metadata": {
        "id": "GOhuhZPFUrcv"
      },
      "outputs": [],
      "source": [
        "# Train the best model\n",
        "def train_eval_best_model(best_params):\n",
        "    lr = float(best_params['lr'])\n",
        "    batch_size = int(best_params['batch_size'])\n",
        "    unfreeze = int(best_params['unfreeze'])\n",
        "    weight_decay = float(best_params['weight_decay'])\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
        "\n",
        "    # Load the data\n",
        "    dataset, train_dataloader, val_dataloader, test_dataloader = load_data(batch_size)\n",
        "\n",
        "    # Load the model\n",
        "    model = load_vit(num_classes=len(dataset.classes), unfreeze=unfreeze).to(device)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    with mlflow.start_run(run_name=\"best_model\"):\n",
        "        # Log the parameters to mlflow\n",
        "        mlflow.log_param(\"lr\", lr)\n",
        "        mlflow.log_param(\"batch_size\", batch_size)\n",
        "        mlflow.log_param(\"unfreeze\", unfreeze)\n",
        "        mlflow.log_param(\"weight_decay\", weight_decay)\n",
        "\n",
        "        epochs = 5\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            train_loss, train_acc = train(model, train_dataloader, criterion, optimizer, device)\n",
        "            val_loss, val_acc = eval(model, val_dataloader, criterion, device)\n",
        "\n",
        "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
        "            mlflow.log_metric(\"train_acc\", train_acc, step=epoch)\n",
        "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
        "            mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Check the test set\n",
        "        test_loss, test_acc = eval(model, test_dataloader, criterion, device)\n",
        "        mlflow.log_metric(\"test_loss\", test_loss)\n",
        "        mlflow.log_metric(\"test_acc\", test_acc)\n",
        "\n",
        "        # Log the best model\n",
        "        mlflow.pytorch.log_model(model, \"vit_eurosat_best_model\")\n",
        "        torch.save(model.state_dict(), \"vit_eurosat_best_model.pth\")\n",
        "        mlflow.log_artifact(\"vit_eurosat_best_model.pth\")\n",
        "\n",
        "    return model, test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EQaiOo4_a-Pe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQaiOo4_a-Pe",
        "outputId": "697cef92-bd19-42d9-f4b2-a8bbdb034bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Train Loss: 0.3763, Train Acc: 90.46%, Val Loss: 0.1282, Val Acc: 95.95%\n",
            "Epoch [2/5], Train Loss: 0.0784, Train Acc: 97.57%, Val Loss: 0.1061, Val Acc: 96.57%\n",
            "Epoch [3/5], Train Loss: 0.0439, Train Acc: 98.78%, Val Loss: 0.0849, Val Acc: 97.09%\n",
            "Epoch [4/5], Train Loss: 0.0261, Train Acc: 99.35%, Val Loss: 0.1040, Val Acc: 96.79%\n",
            "Epoch [5/5], Train Loss: 0.0147, Train Acc: 99.71%, Val Loss: 0.0800, Val Acc: 97.58%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/04/14 23:06:53 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2025/04/14 23:07:04 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.21.0+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torchvision==0.21.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "\u001b[31m2025/04/14 23:07:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(VisionTransformer(\n",
              "   (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "   (encoder): Encoder(\n",
              "     (dropout): Dropout(p=0.0, inplace=False)\n",
              "     (layers): Sequential(\n",
              "       (encoder_layer_0): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_1): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_2): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_3): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_4): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_5): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_6): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_7): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_8): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_9): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_10): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "       (encoder_layer_11): EncoderBlock(\n",
              "         (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (self_attention): MultiheadAttention(\n",
              "           (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "         )\n",
              "         (dropout): Dropout(p=0.0, inplace=False)\n",
              "         (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "         (mlp): MLPBlock(\n",
              "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "           (1): GELU(approximate='none')\n",
              "           (2): Dropout(p=0.0, inplace=False)\n",
              "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "           (4): Dropout(p=0.0, inplace=False)\n",
              "         )\n",
              "       )\n",
              "     )\n",
              "     (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "   )\n",
              "   (heads): Sequential(\n",
              "     (head): Linear(in_features=768, out_features=10, bias=True)\n",
              "   )\n",
              " ),\n",
              " 0.07656481636987056,\n",
              " 97.62962962962963)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_eval_best_model(best_params)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
